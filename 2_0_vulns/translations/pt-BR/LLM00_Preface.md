## Carta dos Líderes do Projeto

O OWASP Top 10 para Aplicações de Grandes Modelos de Linguagem começou em 2023 como um esforço comunitário para destacar e abordar questões de segurança específicas de aplicações de IA. Desde então, a tecnologia continuou a se espalhar por diversas indústrias e aplicações, assim como os riscos associados. À medida que os LLMs são incorporados mais profundamente em tudo, desde interações com clientes até operações internas, desenvolvedores e profissionais de segurança estão descobrindo novas vulnerabilidades—e maneiras de mitigá-las.

A lista de 2023 foi um grande sucesso ao aumentar a conscientização e estabelecer uma base para o uso seguro de LLMs, mas aprendemos ainda mais desde então. Nesta nova versão de 2025, trabalhamos com um grupo maior e mais diverso de colaboradores ao redor do mundo, todos ajudando a moldar esta lista. O processo envolveu sessões de brainstorming, votações e feedback do mundo real de profissionais que lidam diretamente com a segurança de aplicações LLM, seja contribuindo ou refinando as entradas através de suas opiniões. Cada voz foi crucial para tornar este novo lançamento o mais completo e prático possível.

### Novidades no Top 10 de 2025

A lista de 2025 reflete uma melhor compreensão dos riscos existentes e introduz atualizações críticas sobre como os LLMs são usados em aplicações do mundo real hoje. Por exemplo, **Consumo Descontrolado** expande o que antes era Negação de Serviço para incluir riscos relacionados à gestão de recursos e custos inesperados—um problema premente em implementações de LLM em larga escala.

A entrada **Vetores e Embeddings** responde aos pedidos da comunidade por orientações sobre como proteger a Recuperação-Baseada em Geração (RAG) e outros métodos baseados em embeddings, que agora são práticas centrais para fundamentar saídas dos modelos.

Também adicionamos **Vazamento de Prompt do Sistema** para abordar uma área com explorações no mundo real que foram altamente solicitadas pela comunidade. Muitas aplicações presumiam que os prompts eram isolados de forma segura, mas incidentes recentes mostraram que os desenvolvedores não podem assumir com segurança que as informações nesses prompts permanecem secretas.

**Agência Excessiva** foi expandida, dado o uso crescente de arquiteturas agenticas que podem dar mais autonomia ao LLM. Com os LLMs agindo como agentes ou em configurações de plug-in, permissões não controladas podem levar a ações não intencionais ou arriscadas, tornando esta entrada mais crítica do que nunca.

### Próximos Passos

Assim como a própria tecnologia, esta lista é um produto dos insights e experiências da comunidade de código aberto. Ela foi moldada por contribuições de desenvolvedores, cientistas de dados e especialistas em segurança de diversos setores, todos comprometidos em construir aplicações de IA mais seguras. Estamos orgulhosos de compartilhar esta versão de 2025 com você e esperamos que ela forneça as ferramentas e o conhecimento necessários para proteger os LLMs de forma eficaz.

Obrigado a todos que ajudaram a concretizar este trabalho e àqueles que continuam a usá-lo e melhorá-lo. Estamos gratos por fazer parte desta jornada com vocês.

### @ Steve Wilson  
Líder do Projeto  
OWASP Top 10 para Aplicações de Grandes Modelos de Linguagem  
LinkedIn: [https://www.linkedin.com/in/wilsonsd/](https://www.linkedin.com/in/wilsonsd/)  

### @ Ads Dawson  
Líder Técnico & Líder de Entradas de Vulnerabilidade  
OWASP Top 10 para Aplicações de Grandes Modelos de Linguagem  
LinkedIn: [https://www.linkedin.com/in/adamdawson0/](https://www.linkedin.com/in/adamdawson0/)
